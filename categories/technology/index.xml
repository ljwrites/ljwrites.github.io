<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Technology on Semi-author-ized writer</title>
    <link>http://ljwrites.blog/categories/technology/</link>
    <description>Recent content in Technology on Semi-author-ized writer</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>CC BY-NC</copyright>
    <lastBuildDate>Sat, 10 Dec 2022 00:00:00 +0900</lastBuildDate><atom:link href="http://ljwrites.blog/categories/technology/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Object storage on Mastodon with a Backblaze B2 bucket</title>
      <link>http://ljwrites.blog/posts/mastodon-b2/</link>
      <pubDate>Sat, 10 Dec 2022 00:00:00 +0900</pubDate>
      
      <guid>http://ljwrites.blog/posts/mastodon-b2/</guid>
      <description>Here&amp;rsquo;s how I set up a Backblaze B2 bucket with a local proxy for Mastodon object storage.</description>
      <content:encoded><![CDATA[<h2 id="a-little-background-and-why-b2">A little background &amp; why B2?</h2>
<p>It was kind of background knowledge for me that object storage was an option in Mastodon hosting, but I never felt much need for it on my tiny instance.
Then it became an urgent issue when fedi activity exploded in November in the wake of the Twitter meltdown.
My instance database started crashing from the 40 GB local drive overflowing with cached media, and constantly ran at above 30 GB even when I left only one day&rsquo;s worth of cache at media cleanup (<code>tootctl media remove --days 1</code>).</p>
<p>I already had a Backblaze/B2 account that I had been using for my personal offsite backups, and I calculated that I could similarly hook it up to my Hometown/Mastodon instance at a fraction of the cost of adding more storage volume to the Hetzner server.
I also wanted to keep using B2 for this rather than create a new account with AWS or some other storage service, feeling no need to complicate things with yet another account and service to keep track of.</p>
<p>The problem I ran into was that this particular combination of Mastodon and B2 is <em>woefully</em> underdocumented, even with B2&rsquo;s S3-compatibility.
This led me into a lot of trial and error because the documentation I did find was outdated<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> and/or did not mention issues unique to B2, like a huge authentication pitfall that I ended up pitching headfirst into.</p>
<p>Let me discuss that pitfall first, in case you don&rsquo;t need the rest of this guide:
<strong>You need to use a B2 application key, NOT a master application key, for this purpose.</strong>
If, like me, you have everything set up correctly and media uploads fail for an unexplained reason, this might be why.
More details in Step 1 below.</p>
<p>So here it is, the walkthrough of the process and settings that I wished I had when I configured my setup, put together from other sources and my own trial and error.</p>
<h2 id="step-1-set-up-a-b2-bucket-and-application-key-for-your-instance">Step 1: Set up a B2 bucket and application key for your instance</h2>
<p>This part is going to be pretty obvious if you already use B2.
Otherwise, the <a href="https://help.backblaze.com/hc/en-us/articles/1260803542610-Creating-a-B2-Bucket-using-the-Web-UI">official tutorial for creating a bucket</a> should be enough.
Everything I have read says the privacy setting of the bucket should be public, though this comes at a risk because it means anyone can download from the bucket which could potentially eat into your traffic limit and cost you.
If you haven&rsquo;t done so already, you might have to verify your email to set the bucket to public.</p>
<p>Make note of the bucket&rsquo;s address, which will be the endpoint noted in your bucket information preceded by your bucket name.
If you named your bucket <code>my-instance-media</code> your bucket address would be something like:</p>
<p>my-instance-media.s3.us-west-900.backblazeb2.com</p>
<p>You can verify this by uploading a file to the bucket and viewing the address of the file, which will be something like:</p>
<p>my-instance-media.s3.us-west-900.backblazeb2.com/my-test-file.txt</p>
<p>If you don&rsquo;t have a B2 application key, <a href="https://help.backblaze.com/hc/en-us/articles/360052129034-Creating-and-Managing-Application-Keys">their official tutorial</a> should get you started.
Also, as discussed above, make sure you use a <strong>non-master</strong> application key pair for this setup in Step 4 below.
Master application keys are <a href="https://kb.msp360.com/cloud-vendors/backblazeb2/backblazeb2-as-s3compatible">NOT S3-compatible</a> (see &ldquo;Warning&rdquo;), and if you set up your <code>.env.production</code> with it your setup will not work!</p>
<p>Note down the application key id-application key pair in a secure location such as your password manager, especially the application key which will only be shown once and never again in your browser interface or otherwise.</p>
<h2 id="step-2-set-up-a-proxy-on-nginx">Step 2: Set up a proxy on nginx</h2>
<p>As noted in the official Mastodon documentation, it is very much recommended that you set up a proxy local to the server to cache  media requested from the bucket on your server.
If every request were to go directly to your bucket your traffic meter could climb rapidly and cost you more money than it has to.
I modeled my nginx configuration for this on <a href="https://thomas-leister.de/en/mastodon-s3-media-storage/">a configuration for a different S3-compatible service</a>, and followed the directions in the <a href="https://docs.joinmastodon.org/admin/optional/object-storage-proxy/">Mastodon documentation</a> on configuring the proxy.</p>
<p>Here&rsquo;s what my configuration, anonymized to <code>/etc/nginx/sites-available/files.example.com</code>, looks like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>    proxy_cache_path   /tmp/nginx-cache-instance-media levels<span style="color:#f92672">=</span>1:2 keys_zone<span style="color:#f92672">=</span>s3_cache:10m max_size<span style="color:#f92672">=</span>10g
</span></span><span style="display:flex;"><span>    inactive<span style="color:#f92672">=</span>48h use_temp_path<span style="color:#f92672">=</span>off;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    server <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      listen <span style="color:#ae81ff">443</span> ssl http2;
</span></span><span style="display:flex;"><span>      listen <span style="color:#f92672">[</span>::<span style="color:#f92672">]</span>:443 ssl http2;
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># CUSTOMIZE THE VALUE BELOW TO YOUR OWN SUBDOMAIN</span>
</span></span><span style="display:flex;"><span>      server_name files.example.com;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      root /home/mastodon/live/public/system;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      access_log off;
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># CUSTOMIZE THE VALUE BELOW TO YOUR DESIRED ERROR LOG FILE NAME</span>
</span></span><span style="display:flex;"><span>      error_log /var/log/nginx/files-error.log;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      keepalive_timeout 60;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      location <span style="color:#f92672">=</span> / <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        index index.html;
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      location / <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>        try_files $uri @s3;
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># CUSTOMIZE THE VALUE BELOW TO YOUR BUCKET ADDRESS</span>
</span></span><span style="display:flex;"><span>      set $s3_backend <span style="color:#e6db74">&#39;https://my-instance-media.s3.us-west-900.backblazeb2.com&#39;</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> location @s3 <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>   limit_except GET <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>     deny all;
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>   resolver 9.9.9.9;
</span></span><span style="display:flex;"><span>   <span style="color:#75715e"># CUSTOMIZE THE VALUE BELOW TO YOUR BUCKET ADDRESS</span>
</span></span><span style="display:flex;"><span>   proxy_set_header Host <span style="color:#e6db74">&#39;my-instance-media.s3.us-west-900.backblazeb2.com&#39;</span>;
</span></span><span style="display:flex;"><span>   proxy_set_header Connection <span style="color:#e6db74">&#39;&#39;</span>;
</span></span><span style="display:flex;"><span>   proxy_set_header Authorization <span style="color:#e6db74">&#39;&#39;</span>;
</span></span><span style="display:flex;"><span>   proxy_hide_header Set-Cookie;
</span></span><span style="display:flex;"><span>   proxy_hide_header <span style="color:#e6db74">&#39;Access-Control-Allow-Origin&#39;</span>;
</span></span><span style="display:flex;"><span>   proxy_hide_header <span style="color:#e6db74">&#39;Access-Control-Allow-Methods&#39;</span>;
</span></span><span style="display:flex;"><span>   proxy_hide_header <span style="color:#e6db74">&#39;Access-Control-Allow-Headers&#39;</span>;
</span></span><span style="display:flex;"><span>   proxy_hide_header x-amz-id-2;
</span></span><span style="display:flex;"><span>   proxy_hide_header x-amz-request-id;
</span></span><span style="display:flex;"><span>   proxy_hide_header x-amz-meta-server-side-encryption;
</span></span><span style="display:flex;"><span>   proxy_hide_header x-amz-server-side-encryption;
</span></span><span style="display:flex;"><span>   proxy_hide_header x-amz-bucket-region;
</span></span><span style="display:flex;"><span>   proxy_hide_header x-amzn-requestid;
</span></span><span style="display:flex;"><span>   proxy_ignore_headers Set-Cookie;
</span></span><span style="display:flex;"><span>   proxy_pass $s3_backend$uri;
</span></span><span style="display:flex;"><span>   proxy_intercept_errors off;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>   proxy_cache s3_cache;
</span></span><span style="display:flex;"><span>   proxy_cache_valid <span style="color:#ae81ff">200</span> <span style="color:#ae81ff">304</span> 48h;
</span></span><span style="display:flex;"><span>   proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;
</span></span><span style="display:flex;"><span>   proxy_cache_lock on;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>   expires 1y;
</span></span><span style="display:flex;"><span>   add_header Cache-Control public;
</span></span><span style="display:flex;"><span>   add_header <span style="color:#e6db74">&#39;Access-Control-Allow-Origin&#39;</span> <span style="color:#e6db74">&#39;*&#39;</span>;
</span></span><span style="display:flex;"><span>   add_header X-Cache-Status $upstream_cache_status;
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><p>The specific addresses and names should be customized to your desired settings, as marked in the configuration text.</p>
<p>When the configuration file is written to your satisfaction, save it and symlink it from <code>/etc/nginx/sites-enabled</code>, and reload nginx by running (with <code>sudo</code> if you are not the <code>root</code> user here):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ln -s /etc/nginx/sites-available/files.example.com /etc/nginx/sites-enabled/
</span></span><span style="display:flex;"><span>systemctl reload nginx
</span></span></code></pre></div><p>Then get a SSL certificate for the domain, as seen in the Mastodon documentation.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>certbot --nginx -d files.example.com
</span></span><span style="display:flex;"><span>systemctl reload nginx
</span></span></code></pre></div><p>This was the main place I diverged from the configuration posted on the thomas-leister.de website, by the way:
I use port 443 for an encrypted connection per the Mastodon documentation rather than 80 for an unencrypted one like Thomas Leister did, mainly because the unencrypted connection broke all the images on my instance lol.</p>
<h2 id="step-3-upload-existing-mastodon-media-to-your-bucket">Step 3: Upload existing Mastodon media to your bucket</h2>
<p>If your instance is already in use, you should upload previously downloaded media to the instance bucket.
There are several different tools to achieve this, and if you already use an S3-compatible tool like <code>aws</code> or <code>s3cmd</code> it should do the job.
Just be aware that you&rsquo;ll need to use an S3-compatible <strong>non</strong>-master B2 application key to authenticate it, as discussed.</p>
<p>I used the official <code>b2</code> command line tool, since it&rsquo;s a simple binary and fairly easy to use.
I downloaded b2 for Linux through the link on <a href="https://www.backblaze.com/b2/docs/quick_command_line.html">this page</a>, uploaded it to the <code>/home/mastodon/live</code> directory (though in hindsight its <code>bin</code> subdirectory would have been more fitting), changed the owner to the mastodon user with:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo chown mastodon:mastodon b2-linux
</span></span></code></pre></div><p>Switched to the mastodon user:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo su - mastodon
</span></span></code></pre></div><p>Changed the file name to <code>b2</code> for simplicity&rsquo;s sake:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mv b2-linux b2
</span></span></code></pre></div><p>Also gave it execution permission.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>chmod +x b2
</span></span></code></pre></div><p>I didn&rsquo;t mess with <code>$PATH</code> or anything like that, since this wasn&rsquo;t going to be an everyday operation.</p>
<p>You can then create an authentication profile using the application key ID and application key pair generated in Step 1 above.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>./b2 authorize-account --profile my-instance $B2_Application_Key_ID $B2_Application_Key
</span></span></code></pre></div><p>The variables <code>$B2_Application_Key_ID</code> and <code>$B2_Application_Key</code> should be replaced by the actual values, of course.
Or you can actually define the variables I guess, but I didn&rsquo;t feel the need since authentication was a one-time thing and, once successful, the switch <code>--profile my-instance</code> is enough to authenticate all operations.</p>
<p>After setting up the profile with <code>authorize-account</code> you can use some short, harmless command like list-buckets to test whether authentication works:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>./b2 list-buckets --profile my-instance
</span></span></code></pre></div><p>Or maybe try uploading a small file or something.
The <code>--help</code> switch is helpful for figuring out the commands and syntax, or simply running b2 without any arguments will also bring up the help options.</p>
<p>Once authentication is confirmed to work, sync the <code>public/system</code> directory to the remote b2 bucket using the <code>sync</code> command.
If you haven&rsquo;t already, it&rsquo;s a good idea to run some <a href="https://docs.joinmastodon.org/admin/tootctl/#media-remove">media cleanup commands</a> to minimize the amount of files to upload to the bucket.
Here are the ones I used, from <code>/home/mastodon/bin</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>  ./tootctl media remove --days <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>./tootctl media remove --prune-profiles
</span></span><span style="display:flex;"><span>./tootctl media remove --remove-headers
</span></span></code></pre></div><p>When you are ready to start moving the files, assuming the command is run from the <code>/home/mastodon/live</code> directory:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>./b2 sync --profile my-instance ./public/system/ b2://my-instance-media/
</span></span></code></pre></div><p>You can read more about  <a href="https://b2-command-line-tool.readthedocs.io/en/master/subcommands/sync.html">b2&rsquo;s sync command options</a>, but I found the default options satisfactory.</p>
<h2 id="step-4-mastodon-configuration">Step 4: Mastodon configuration</h2>
<p>My Mastodon configuration in <code>live/.env.production</code> to enable the object storage looks something like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>S3_ENABLED<span style="color:#f92672">=</span>true
</span></span><span style="display:flex;"><span>S3_PROTOCOL<span style="color:#f92672">=</span>https
</span></span><span style="display:flex;"><span><span style="color:#75715e"># EVERYTHING BELOW THIS POINT SHOULD BE CUSTOMIZED</span>
</span></span><span style="display:flex;"><span>S3_BUCKET<span style="color:#f92672">=</span>my-instance-media
</span></span><span style="display:flex;"><span>AWS_ACCESS_KEY_ID<span style="color:#f92672">=</span>$B2_Application_Key_ID
</span></span><span style="display:flex;"><span>AWS_SECRET_ACCESS_KEY<span style="color:#f92672">=</span>$B2_Application_Key
</span></span><span style="display:flex;"><span>S3_ALIAS_HOST<span style="color:#f92672">=</span>files.example.com
</span></span><span style="display:flex;"><span>S3_HOSTNAME<span style="color:#f92672">=</span>files.example.com
</span></span><span style="display:flex;"><span>S3_REGION<span style="color:#f92672">=</span>us-west-900
</span></span><span style="display:flex;"><span>S3_ENDPOINT<span style="color:#f92672">=</span>https://s3.us-west-900.backblazeb2.com
</span></span></code></pre></div><p>In addition to the earlier point that the application key ID and application key pair should have been generated as a non-master application key, also note the <code>https://</code> in front of the <code>S3_ENDPOINT</code> value.
For me that was the final hurdle to getting the setup to work.</p>
<p>Switch to admin or some other user with <code>sudo</code> power.
From the mastodon user, it just takes an <code>exit</code> command in my case. Restart the Mastodon processes:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl restart mastodon-*.service
</span></span></code></pre></div><p>Check if the instance works normally.
If it&rsquo;s down, the API call to Backblaze storage may be failing and the key id and application key values should be double-checked.</p>
<h2 id="step-5-check-if-object-storage-is-working">Step 5: Check if object storage is working</h2>
<p>As discussed in the <a href="https://thomas-leister.de/en/mastodon-s3-media-storage/">Thomas Leister writeup</a> (&ldquo;Checking if it works&rdquo;), check the browser&rsquo;s console to see if the correct server proxy is loading up for media, and whether media are properly displayed.</p>
<p>Also, try attaching a piece of media to a post.
If the attachment fails with a 500 error, you need to check your settings.</p>
<p>Even after I ironed out the authentication issues with the application key I found media uploads were, understandably, slower than before and they sometimes timed out.
This was why I set the <code>keepalive_timeout</code> value to 60 rather than 30 in the nginx proxy settings and image uploads have not timed out since.</p>
<p>Though Mastodon will be uploading new media to the remote bucket and requesting it remotely, for preexisting media files it will look to the local <code>public/system</code> directory first.
This can make it harder to tell if the bucket setup is working or it&rsquo;s just the local storage doing the work, so if you&rsquo;re impatient you can get rid of that directory to force the instance to load everything from the bucket instead.
From <code>/home/mastodon/live/public</code> you can run:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mv system/ system_/
</span></span></code></pre></div><p>to change the name of the <code>system</code> directory without immediately deleting everything in it.</p>
<p>You can&rsquo;t simply leave <code>public/system</code> missing, though, if you want to keep the nginx proxy settings as they are.
Guess who found out the hard way this will crash the instance&hellip; :&rsquo;)
Instead, create a new empty <code>system</code> directory so the setting will have somewhere to look to and not throw an error.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir system
</span></span></code></pre></div><p>If the media still loads properly after this, and new media is fetched and uploaded, it means the setup is working.
Yay!</p>
<h2 id="cleanup-afterwork-and-thoughts">Cleanup, afterwork and thoughts</h2>
<p>You can let this setup run a few days to see whether it keeps working, doesn&rsquo;t overrun your traffic meters etc., before you empty out your local <code>public/system</code> directory, or delete <code>public/system_</code> if you did the directory switch I detailed above.
I can tell you it was quite a weight off to reclaim half my disk space from all that media.</p>
<p>I also ran some <a href="https://docs.joinmastodon.org/admin/tootctl/#accounts-refresh">accounts refresh</a> jobs because I had missing remote profile pics from emergency media deletions, back when my disk had overflowed and the database crashed.
Yeah, things were that bad.</p>
<p>Media loads correctly again on my instance, though there is an initial loading time, and I can get a proper media cache going without my disk at constant risk of running out.
Instance management has become enjoyable again without the constant risk of unplanned server downtime, and I am now able to consider putting other services on the server.</p>
<p>In the long term, media storage is something federated software and communities are going to have to figure out.
Services like <a href="https://jortage.com/">Jortage</a> look interesting, and something like it may be the future of media storage in the fediverse.
For now I have found a solution that works for my instance, and if this write-up helps others avoid some of my confusion and mistakes I will be happy&ndash;although, let&rsquo;s be real, these tech posts have mainly been helpful to myself for the purpose of record-keeping and documentation.</p>
<p>(Updated on 12/18/2023: Fixed a line break in the first line of the nginx configuration, added an advisory to clean up media before syncing.)</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>For instance, there was a gist stating that Mastodon could not directly interface with B2 for object storage because B2 was not S3-compatible, and MinIO would be needed as a relay. This was seemingly confirmed by documentation from Backblaze itself stating its S3 incompatibility. Turns out this was back in 2019-2020 and, as of late 2022, B2 is S3 compatible and MinIO no longer provides the relay function. Guess who only realized this after installing MinIO.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Resolving Arch Linux 404 and Dependency Errors</title>
      <link>http://ljwrites.blog/posts/arch-linux-404-dependency/</link>
      <pubDate>Mon, 12 Jul 2021 00:00:00 +0900</pubDate>
      
      <guid>http://ljwrites.blog/posts/arch-linux-404-dependency/</guid>
      <description>Update the package database and manually resolve dependencies.</description>
      <content:encoded><![CDATA[<p>Hey Arch Linux user!</p>
<p>Do you keep getting 404 errors when you try to install packages?
Did you rewrite your <code>/etc/pacman.d/mirrorlist</code> file for what feels like dozens of times?
Did you edit your <code>/etc/pacman.conf</code> file according to this Stack Exchange and forum post or that, hoping to get things to work?</p>
<p>If so, these tips just might help.
That&rsquo;s where I was, to the point of almost ragequitting Arch altogether, but trying these tips helped.</p>
<h2 id="update-the-package-database">Update the package database</h2>
<p>If you have your <code>mirrorlist</code> file arranged so the ones geographically closer to you are on top, it may be that you need to update your database.
You might want to try updating your package database with:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ sudo pacman -Sy
</span></span></code></pre></div><p>Or you could do a full system upgrade with <code>-Syu</code>, your choice.
This landed me in dependency hell, though, see below, so I opted for just a database update this time around and it worked for me.</p>
<p>The reason 404 errors are common in Arch, according to a forum post I saw, is that old packages are deleted on the servers.
Therefore, if your package database is outdated <code>pacman</code> will ask for old deleted versions of packages, resulting in 404 errors.</p>
<p>Live and learn, right?</p>
<h2 id="the-next-level-dependency-hell">The next level: Dependency hell</h2>
<p>After updating the database Arch finally seemed ready to start installing packages again, but this time I fell into the dread&hellip; dependency hell.
It consisted of messages like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>:: poppler<span style="color:#f92672">(</span>21.07.0-1<span style="color:#f92672">)</span> 설치로 의존성 <span style="color:#e6db74">&#39;poppler=21.06.1&#39;</span><span style="color:#f92672">(</span>poppler-glib가 요구<span style="color:#f92672">)</span>가 깨집니다
</span></span></code></pre></div><p>Which, translated into English, means that the package I was trying to install (kdenlive) required I upgrade <code>poppler</code> to version 21.07.0-1, which would break the dependency of <code>poppler-glib</code> on version 21.06.1.
Evidenly this would ultimately lead to a dependency breakage of Gnu Image Manipulation Program via <code>gegl</code>&rsquo;s dependency on that specific version of <code>poppler-glib</code>.</p>
<p>Running the install command with <code>--ignore poppler</code> didn&rsquo;t help, since pacman refused to install without the poppler upgrade.
Nor did trying to install with <code>sudo pacman -Sdd kdenlive</code> help, since this resulted in kdenlive installing without any dependencies and the package simply did not work.</p>
<p>So what I did was upgrade the offending dependency by itself, which was feasible in my case because there was just one, specifying a <code>-d</code> switch so the dependency version check was ignored:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ sudo pacman -Sd poppler
</span></span></code></pre></div><p>When I tried the kdenlive installation again it worked, and luckily the Image Manipulation Program wasn&rsquo;t broken by the poppler upgrade.
It very well could have been, though, since upgrades to dependencies do cause breakages.
That&rsquo;s why dependency version checks exist in the first place.</p>
<p>By ignoring dependency version checks, therefore, you do assume the risk of dependency breakages causing malfunctions, which is a long-running issue in the open source world.
Arch Linux, in particular, only allows one version of each package, raising the risk of dependency breakages&ndash;not a good combination with its fast-moving updates.</p>
<p>It should also be noted that running the kdenlive install with one <code>-d</code> switch instead of two might have had a similar result as installing the dependency package with <code>-d</code>, maybe in conjunction with <code>--ignore poppler</code>.
According to <code>man pacman</code> one <code>-d</code> switch just ignores dependency version checks while repeating it twice like I did ignores all dependencies, which in this case meant the app wouldn&rsquo;t work.</p>
<h2 id="keep-arching-on-dot-dot-dot-or-not">Keep Arching on&hellip; or not</h2>
<p>I don&rsquo;t claim these tips will solve every problem with the Arch package manager, but they could be helpful if your mirrorlist seems more or less in order yet all mirrors are failing with 404 errors.
And if dependency conflicts are tying up your package installations and system updates after the 404 errors are resolved, the second part of the advice would come into play.
If you don&rsquo;t want the risk of broken dependencies, or if ignoring dependencies result in apps breaking, you should file a bug report with the relevant projects.</p>
<p>It&rsquo;s also a valid choice to decide that maybe Arch Linux isn&rsquo;t for you if you find these issues to be too much trouble.
Arch is a purposefully fast-moving distribution and by design requires a level of expertise or at least bloody-mindedness.
There are user-friendlier Arch-based distributions like Manjaro that stay a little behind the development curve and are said to be more stable as a result.
The price is in staler packages than mainline Arch, but it&rsquo;s my understanding packages are still newer than in something like Debian.
Besides, truly cutting-edge users don&rsquo;t find even Arch packages new enough and turn to the Arch User Repository for development versions or compile directly from project Git repos.</p>
<p>In the end you have to decide how important newer packages and upgrades are to you, and how much hassle you&rsquo;re willing to put up with.
If you want to keep going with Arch Linux, hopefully this post is helpful to you.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>How I Got into Emacs</title>
      <link>http://ljwrites.blog/posts/how-i-got-into-emacs/</link>
      <pubDate>Sat, 19 Jun 2021 00:00:00 +0900</pubDate>
      
      <guid>http://ljwrites.blog/posts/how-i-got-into-emacs/</guid>
      <description>The true gift of Emacs may be the ability to make it your own in every sense.</description>
      <content:encoded><![CDATA[<p>From time to time I&rsquo;m asked, perhaps especially as a non-dev who uses Emacs every day, how I got into what is considered development software and one seen as esoteric and antiquated at that.
I thought I&rsquo;d write about my experience with Emacs and the advice I would personally give to people who are thinking of getting into it.</p>
<h2 id="destination-emacs">Destination: Emacs</h2>
<p>It probably helped lead me to Emacs that I&rsquo;ve been a hobby coder for decades and like to fiddle with computers.
I&rsquo;m known as the tech person in my family, and have written small apps in Python 2 including an IRC dicebot in the 00&rsquo;s.
(Yes, I&rsquo;m That old.)
I&rsquo;ve used PHP and MySQL to run hosted blogs; I&rsquo;ve tried Ubuntu and now use an Arch Linux installation daily.
Coding and computers don&rsquo;t scare me, and what I lack in expertise and training I make up for in sheer determination and willingness to pour countless hours into solving a problem (thanks, ADHD hyperfocus!!).
So in a way a developer&rsquo;s tool like Emacs was a natural fit for me.</p>
<p>Even so, I don&rsquo;t think I would have bothered with something as complex as Emacs if it weren&rsquo;t for my growing discontentment with the software I used in my writing.
LibreOffice was and is my favorite word processor but still, it&rsquo;s a word processor.
They have their uses and are necessary for my work, but the mix of formatting and content was constraining for first drafts, and the completely linear treatment of the text did not lend itself to flexible thinking about the text and content.
Ultimately, in my workflow, word processors are for presenting text, not creating it.</p>
<p>Scrivener was great while it lasted.
At the time it was a completely new paradigm of writing software for me, with the ability to make text modular and to rearrange it, and snapshots as a rudimentary form of version control.
Still, it too had its problems.
The lack of certain functions like mobile editing, good collaboration support, and portable files became increasingly glaring.
The last straw came when I was locked out of software I had paid for&ndash;twice, on Windows and later Macbook!&ndash;due to the company&rsquo;s server problems.
Shortly afterward I moved to Linux for the reasons discussed in <a href="https://linuxrig.com/2021/03/31/the-linux-setup-l-j-lee-translator-researcher-writer/">my Linux Setup submission</a>, and using Scrivener became a moot point anyway.
Years of experience with Scrivener did give me a better idea of what I wanted in a piece of writing software, however:
Separation of content and presentation, version control, and the ability to move pieces of text around and edit them individually.
I also wanted them in a form that couldn&rsquo;t be arbitrarily locked down, corrupted, or otherwise made inaccessible.</p>
<p>Obviously, I learned over time that the things I wanted were doable by editing in plain text formats.
I looked around for plaintext editing options that would also allow for making text modular.
LaTeX was in serious running for a while and I even read a book about it before deciding it wasn&rsquo;t right for me and my non-technical use-case.
AsciiDoc was great and I worked on a fair number of projects with it writing on Vim, which was when I completely fell in love with Vim&rsquo;s editing capabilities.
The modular treatment of text was incomplete at best under this format and software combination, however.</p>
<p>I thought about writing an Atom plugin or even writing a text editor myself to get the functions I wanted&ndash;yeah, that would have gone well lol&ndash;before, as so many do, I found out about Emacs and Org Mode.
(Update 2022-10-22: And, of course, GitHub has since <a href="https://github.blog/2022-06-08-sunsetting-atom/">pulled the plug on Atom</a> while Emacs is still going as it has for decades before Atom ever existed.)
Through my research I learned Org had everything I was looking for, could be exported to a bunch of other formats, <em>and</em> that it emulated Vim commands through Evil Mode.
Sold, sold, and sold.
I decided to make the jump.
I installed Emacs and very slowly started trying things on it and learning the ropes.</p>
<h2 id="building-up-my-emacs-configuration">Building up my Emacs configuration</h2>
<p>It took me a while to &ldquo;warm up&rdquo; to real configuration work on Emacs.
I used it intermittently  for months with the default splash screen enabled (cringe!), learning basic commands.
I did the built-in tutorial, read or watched some guides like this <a href="https://www.youtube.com/watch?v=oJTwQvgfgMM&amp;t=84s">amazing talk by Org Mode creator Carsten Dominik</a>, and tried to get used to the interface when I had spare time.</p>
<p>At first I didn&rsquo;t even install Evil Mode despite not liking the default Emacs movement keys at all.
For one thing I hadn&rsquo;t figured out the package system yet, and even though it was always the plan to install Evil Mode and its availability was one reason I made the jump from Vim to Emacs, I wanted to give the native Emacs commands a fair shake and at least learn the basics.</p>
<p>I slowly got into things like Org Mode, using the most basic functions which were more than enough at first when I was still new to it.
As Carsten Dominik put it, that&rsquo;s a great thing about Org, that you can start as simply as you like and work your way up to as much or as little complexity as you need.</p>
<p>It was only after months of having at least a shaky grasp of basic Emacs functions that I started doing things like configuring visuals and adding packages, spurred on in part by the Emacs from Scratch videos on the <a href="https://www.youtube.com/channel/UCAiiOTio8Yu69c3XnR7nQBQ">System Crafters</a> channel that was just taking off at the time.
I didn&rsquo; use even a fraction of the advice given on that channel, though.
Instead I mostly used the videos as inspiration and a jumping-off point for more research on how to do specific things when I saw the host doing stuff I wanted for my own setup.</p>
<h2 id="satisfied-mode">Satisfied Mode</h2>
<p>Since then I&rsquo;ve read two books about Emacs, <a href="https://www.oreilly.com/library/view/learning-gnu-emacs/0596006489/">Learning Gnu Emacs</a> and <a href="https://www.masteringemacs.org/">Mastering Emacs</a>.
I found them engaging reads that taught me a lot more about how Emacs works.
I have also been intermittently reading the <a href="https://orgmode.org/manual/">Org Mode Manual</a>, from which I learned a lot of little tricks to make Org more versatile and convenient for me.</p>
<p>Between this and a lot of things I found out through YouTube, Reddit, and online friends, my init.el has grown to a little over 300 lines.
That&rsquo;s tiny in comparison to Emacs veterans, of course, but is in keeping with my motto, as they say, to move slow and fix things.
I&rsquo;m not technically ambitious or highly skilled; I just want a tool that works more or less how I want it to and doesn&rsquo;t require my data to be sent to a company, one that would not stop being supported because it&rsquo;s no longer profitable.
GNU Emacs, configured little by little entirely at my own pace and actively developed for decades by a worldwide team of maintainers and contributors, exactly fits that bill.</p>
<p>The good news is, that means you can use Emacs too as someone who isn&rsquo;t necessarily technologically proficient and just wants a stable working environment, if you don&rsquo;t mind a slow pace and some work including a little coding.</p>
<h2 id="general-advice">General advice</h2>
<p>My best advice based on personal experience? Don&rsquo;t rush it!</p>
<p>Emacs can seem big and intimidating if you want to learn the ins and outs and to customize it to your exact needs, and honestly it <em>is</em> intimidating and time-consuming to do all that.</p>
<p>It becomes more manageable, though, when you start simple and go slowly.
Add configurations and packages as you feel the need and as you become more comfortable with the platform and Emacs Lisp, the language of Emacs.</p>
<p>Going step by step, breaking and then fixing things as you go, will help you understand your configuration and learn with it.
It&rsquo;ll make the dreaded &ldquo;.emacs bankruptcy&rdquo; where your configuration breaks beyond repair less likely, both because your configuration will be easier to debug when it changes in increments and because you understand what went into it.</p>
<p>I guess the above tips my hand on the &ldquo;vanilla or packaged distro&rdquo; issue, too.
By packaged distros I mean distributions like Doom Emacs or Space Emacs that come with a lot of configurations out of the box, with Vim-style keybindings in the case of both Doom and Space Emacs.</p>
<p>To be clear, I&rsquo;m not about to tell anyone not to get an Emacs distro.
They do cool stuff at only a fraction of the time and effort of setting up vanilla Emacs, and I can see why they&rsquo;re popular.
If spending a lot of painstaking effort on configurations isn&rsquo;t your thing and a distro looks right for you, by all means go for it.</p>
<p>That said, I would not install a distro myself because I&rsquo;ve heard stories of the codebase breaking or no longer being supported in some environments.
This is not the kind of risk I&rsquo;m willing to take, to lose an entire working environment I&rsquo;ve come to rely on with no practical way to get it back.
For me vanilla GNU Emacs, configured by my hand, is much more versatile and easier to repair in case something breaks or changes.</p>
<p>Distros are a valid choice depending on your personal balance of stability versus convenience.
I just happen to fall more on the stability side of things, and it doesn&rsquo;t hurt that I actually like to spend time on configurations because I find them fun to do, in reasonable doses.</p>
<p>Above all, I hope you&rsquo;ll have fun with it!
Emacs is a practical and powerful platform, but it can also be a deeply personal project that is molded to you and changes according to your needs, preferences, and growing skill.
Emacs is my main software for writing, my file manager, my task and schedule manager, my email program, my main git interface&hellip; so much of my life is tied into it.
It&rsquo;s an experience like no other I&rsquo;ve had with software and can be a rollercoaster of excitement for the new, the comfort of the familiar, and, I&rsquo;ll be honest, bouts of hair-tearing frustration.
There&rsquo;s also the good, solid satisfaction of crafting a tool you use daily with your own hands, piece by piece.
You can make it uniquely yours if you&rsquo;re willing to put in the work.
That may be the true gift of Emacs, the ability to make it your own in every sense.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>  Troubleshooting &#34;Unmanaged Device&#34; Network Connection Error
  </title>
      <link>http://ljwrites.blog/posts/troubleshoot-network/</link>
      <pubDate>Tue, 15 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>http://ljwrites.blog/posts/troubleshoot-network/</guid>
      <description>Here&amp;rsquo;s how I solved it when there was an unmanaged device error with NetworkManager and systemd.</description>
      <content:encoded><![CDATA[<p>The computer wasn&rsquo;t connecting to the internet this morning with the nm-applet on the status bar saying network connections were unusable.
Sigh. To be fair I had done a system upgrade of Arch Linux the day before, so I guess can this kind of thing Happens.
When I ran:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ nmcli c
</span></span></code></pre></div><p>&hellip;to check wi-fi connections none of was was showing a device, and when I tried to connect to my usual network using</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ nmcli con up <span style="color:#f92672">[</span>device-uuid<span style="color:#f92672">]</span>
</span></span></code></pre></div><p>I got an error that the connection couldn&rsquo;t be activated because &ldquo;No suitable device found for this connection (device lo not available because device is strictly unmanaged).&rdquo;</p>
<p>I searched for the error and, as per <a href="https://askubuntu.com/questions/1190504/why-is-nmcli-not-configuring-device">an answer</a> that was downvoted because it didn&rsquo;t work on Ubuntu but worked for me, I added:</p>
<pre tabindex="0"><code class="language-nil" data-lang="nil">[ifupdown]
managed=true
</code></pre><p>to <code>/etc/NetworkManager/NetworkManager.conf</code>.</p>
<p>Restarted NetworkManager with</p>
<pre tabindex="0"><code class="language-nil" data-lang="nil">$ sudo systemctl restart NetworkManager.service
</code></pre><p>Worked instantly. When I checked connections with <code>$ nmcli c</code> again my usual connection had been assigned my main network device, and the nm-applet updated accordingly.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Mu4e Error in Process Sentinel: Mu Server Process Ended with Exit 1</title>
      <link>http://ljwrites.blog/posts/mu4e-mu-server-process-error/</link>
      <pubDate>Tue, 15 Jun 2021 00:00:00 +0900</pubDate>
      
      <guid>http://ljwrites.blog/posts/mu4e-mu-server-process-error/</guid>
      <description>Shutting down mu server turned out to be effective when mu4e wouldn&amp;rsquo;t start.</description>
      <content:encoded><![CDATA[<p>Because no upgrade goes unpunished, Mu4e was refusing to start up in Emacs, throwing an &ldquo;error in process sentinel: Mu server process ended with exit 1&rdquo; error.
I couldn&rsquo;t find this exact error message online, but a look through posts about similar error messages revealed that complaints about the Mu server were often caused by the server still running.
I took the advice in <a href="https://github.com/djcb/mu/issues/8">this Mu4e issue thread</a> and ran:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pkill -2 -u $UID mu
</span></span></code></pre></div><p>&hellip;exactly like that, without replacing the <code>$UID</code> with anything.
Mu4e sprang right back up afterward, having grabbed control of the database back from the server process that had been running.</p>
<p>Still waiting wearily for more troubles to happen, but in the meantime at least I can read emails again.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>My Simple Directory Backup with a systemd Timer</title>
      <link>http://ljwrites.blog/posts/backup-systemd-timer/</link>
      <pubDate>Sat, 29 May 2021 00:00:00 +0000</pubDate>
      
      <guid>http://ljwrites.blog/posts/backup-systemd-timer/</guid>
      <description>How I set up a systemd timer for regular automated backups of selected directories.</description>
      <content:encoded><![CDATA[<p>I put together an automatic hourly backup of selected directories using rsync and a systemd timer.
It was a little bit more of a hassle than I anticipated, given my complete unfamiliarity with systemd, so I thought I&rsquo;d document it for my own records and in case it&rsquo;s useful to someone else on a distribution with systemd who has a similar use-case to mine.</p>
<h2 id="why-a-systemd-timer-and-not-cron">Why a systemd timer and not cron?</h2>
<p>In my case, mostly because I already have systemd and the timer comes with it, while I&rsquo;d have to install cron.
Evidently a systemd timer also has some advantages over cron such as easy debugging and flexibility.
The Arch Wiki lists some <a href="https://wiki.archlinux.org/title/Systemd/Timers#As%5Fa%5Fcron%5Freplacement">benefits and caveats</a> of using the systemd timer as a cron replacement.</p>
<h2 id="step-1-set-up-the-backup-script">Step 1: Set up the backup script</h2>
<p>I used rsync for the backup script.
While I&rsquo;m not ssh-ing into an external machine and just using an external hard drive, it&rsquo;s simple yet robust enough for this use-case, too.
My backup script file is just a shell script that starts with lines like:</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">8
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e">#!/bin/sh
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Backup documents</span>
</span></span><span style="display:flex;"><span>rsync -a /home/ljwrites/Documents/ /external/hdd/Documents/
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Backup pictures</span>
</span></span><span style="display:flex;"><span>rsync -a /home/ljwrites/Pictures/ /external/hdd/Pictures/
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Backup config folder</span>
</span></span><span style="display:flex;"><span>rsync -a /home/ljwrites/.config /external/hdd/Programs/</span></span></code></pre></td></tr></table>
</div>
</div>
<p>As you may know if you have some familiarity with rsync, the trailing slash on the source is significant.
Without the trailing slash, the files in the source directory are copied into a subdirectory of the destination.
This means that, in the above example, files and diretories from the <code>Documents</code> and <code>Pictures</code> directories are backed up to the <code>Documents</code> and <code>Pictures</code> directories of the external drive.
The files and directories in <code>.config</code>, on the other hand, are backed up to <code>Programs/.config</code> in the external drive.</p>
<p>This file was made executable with <code>chmod +x</code> and lives in my <code>~/.local/bin</code> with the file name <code>backup</code>.
Yeah, I guess it should be <code>backup.sh</code>, but without the extension it&rsquo;s shorter to run manually from the command line and it works.
I am told the more proper way to do this is by creating a symlink named <code>backup</code> to my actual .sh file, but I don&rsquo;t have a separate coding or development directory and I&rsquo;m lazy lol.</p>
<p>Oh, and of course, to call backup in <code>~/.local/bin</code> directly from the command line I had to add <code>~/.local/bin</code> to my <code>$PATH</code>, which I did with a line in <code>.bashrc</code> like this:</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>PATH<span style="color:#f92672">=</span>$HOME/.local/bin:$HOME/go/bin:$PATH</span></span></code></pre></td></tr></table>
</div>
</div>
<p>I put <code>~/.local/bin</code> and <code>~/go/bin</code> ahead of <code>$PATH</code> rather than appending them, btw, because this way my local executables take precedence over the system ones.
If there happens to be a binary called <code>backup</code> in the system files, for instance, when I type <code>backup</code> in the terminal I&rsquo;ll be getting the <code>backup</code> script I wrote.
This was another piece of advice from my dev friend, one that I actually took.</p>
<p>Once the backup script is tested and confirmed to be working, it&rsquo;s time to set up the systemd service and timer.</p>
<h2 id="step-2-set-up-the-systemd-service-and-timer">Step 2: Set up the systemd service and timer</h2>
<p>I wrote a <code>filebackup.service</code> text file that consists of just the following lines:</p>
<pre tabindex="0"><code class="language--n" data-lang="-n">[Unit]
Description=File backup service

[Service]
ExecStart=/home/ljwrites/.local/bin/backup
</code></pre><p>You can set the description to whatever text string you like, and  <code>ExecStart</code> is obviously a call to execute the <code>backup</code> file I put in <code>.local/bin</code>.</p>
<p>And here&rsquo;s my <code>filebackup.timer</code> file:</p>
<pre tabindex="0"><code class="language--n" data-lang="-n">[Unit]
Description=Hourly backup of files

[Timer]
OnCalendar=Hourly
AccuracySec=1s
Persistent=false
Unit=filebackup.service

[Install]
WantedBy=timers.target
</code></pre><p><code>OnCalendar=Hourly</code> sets the hourly interval, and <code>Unit</code> calls the <code>filebackup.service</code> from  above.
I have no idea if <code>timers.target</code> is the best timer for this but it works.
There&rsquo;s a more detailed explanation of timer types on (where else?) <a href="https://unix.stackexchange.com/questions/427346/im-writing-a-systemd-timer-what-value-should-i-use-for-wantedby">Stack Exchange</a>, so check up on that if you&rsquo;re interested.
According to that explanation it looks like basic.target would have worked, too.</p>
<p>I moved both the service and timer files to the <code>/etc/systemd/system</code> directory.</p>
<h2 id="step-3-activate-the-systemd-timer">Step 3: Activate the systemd timer</h2>
<p>You can check the list of timers with:</p>
<pre tabindex="0"><code class="language-nil" data-lang="nil">systemctl list-timers
</code></pre><p>You can include inactive timers with the <code>--all</code> flag:</p>
<pre tabindex="0"><code class="language-nil" data-lang="nil">systemctl list-timers --all
</code></pre><p><code>filebackup.timer</code> shouldn&rsquo;t be on the list yet.
You can add it with:</p>
<pre tabindex="0"><code class="language-nil" data-lang="nil">sudo systemctl enable --now filebackup.timer
</code></pre><p>Check timer list again and it should be there, with the NEXT and LEFT columns set to the start of the next hour.</p>
<p><strong>Update 2021/6/15:</strong> If the NEXT and LEFT columns of the backup timer show up as n/a, it may help to restart it using the following command:</p>
<pre tabindex="0"><code class="language-nil" data-lang="nil">sudo systemctl restart filebackup.timer
</code></pre><h2 id="step-4-check-if-the-backup-ran-with-systemd-journal">Step 4: Check if the backup ran with systemd journal</h2>
<p>You can check if the backup timer is running on schedule with:</p>
<pre tabindex="0"><code class="language-nil" data-lang="nil">sudo journalctl -u filebackup.*
</code></pre><p>I&rsquo;ve set this to an alias because I like the peace of mind in knowing I have regular backups of my stuff.</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>alias backupcheck<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;sudo journalctl -u filebackup.*&#39;</span></span></span></code></pre></td></tr></table>
</div>
</div>
<h2 id="and-that-s-it">And that&rsquo;s it!</h2>
<p>There you have it, my file backup setup.
It&rsquo;s really simple and basic, but does what I need it to do.
It also took me a while to get working properly because I couldn&rsquo;t find specific step-by-step instructions for my particular needs.
Maybe it&rsquo;ll help others who have similar use-cases but are not devs.</p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
